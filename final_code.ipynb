{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "# 손가락 이름\n",
    "finger_names = {8: \"Index\", 12: \"Middle\", 16: \"Ring\", 20: \"Pinky\"}\n",
    "\n",
    "def convertImag(x, y, w, h ,orgImage, overImage ):\n",
    "    # 이미지 경계 검사 및 조정\n",
    "    ih, iw, _ = orgImage.shape\n",
    "    x = max(0, min(x, iw))\n",
    "    y = max(0, min(y, ih))\n",
    "    w = max(0, min(w, iw - x))\n",
    "    h = max(0, min(h, ih - y))\n",
    "    \n",
    "    overlay_image = cv2.resize(overImage, (w, h))\n",
    "\n",
    "    #Separate the color and alpha channels of the overlay image\n",
    "    overlay_img_color = overlay_image[:, :, :3]  # RGB channels\n",
    "    overlay_img_alpha = overlay_image[:, :, 3]  # Alpha channel\n",
    "\n",
    "    # Extract the region of interest (ROI) from the original image\n",
    "    roi = orgImage[y:y+h, x:x+w]\n",
    "\n",
    "    # Use the alpha channel as a mask to blend the overlay and ROI\n",
    "    alpha = overlay_img_alpha / 255.0\n",
    "    inv_alpha = 1.0 - alpha\n",
    "    \n",
    "    for c in range(0, 3):\n",
    "        roi[:, :, c] = (alpha * overlay_img_color[:, :, c] + inv_alpha * roi[:, :, c])\n",
    "    \n",
    "    return roi\n",
    "# 두 랜드마크 사이의 각도를 계산합니다.\n",
    "def calculate_angle(p1, p2):\n",
    "\n",
    "    angle = math.atan2(p2[1] - p1[1], p2[0] - p1[0])\n",
    "    return math.degrees(angle)\n",
    "\n",
    "# 손가락의 상태를 분석하는 함수\n",
    "def analyze_finger_pose(landmarks):\n",
    " # 각 손가락의 끝과 그 다음 관절 인덱스\n",
    "    finger_tips = [8, 12, 16, 20]  # 엄지 제외\n",
    "    lower_joints = [7, 11, 15, 19]\n",
    "    \n",
    "    # 손가락 상태\n",
    "    finger_status = {\"Index\": \"\", \"Middle\": \"\", \"Ring\": \"\", \"Pinky\": \"\"}\n",
    "    #리턴 스트링\n",
    "    ret_message =''\n",
    "\n",
    "    # 엄지는 별도 처리 (엄지 끝: 4, 엄지 첫 번째 관절: 3)\n",
    "    thumb_tip = landmarks[4]\n",
    "    thumb_joint = landmarks[3]\n",
    " \n",
    "    #finger_status[\"Thumb\"] = \"Open\" if thumb_tip[1] <= thumb_joint[1] else \"Closed\"  # x , y , z값이 \n",
    "    # 엄지 손가락 끝과 첫 번째 관절 사이의 각도 계산\n",
    "    thumb_angle = calculate_angle(thumb_tip, thumb_joint)\n",
    "    finger_status[\"Thumb\"] = \"Open\" if thumb_angle > 90 else \"Closed\"  # x , y , z값이 \n",
    "    #finger_status[\"Thumb\"] = thumb_angle \n",
    "    for tip, joint in zip(finger_tips, lower_joints):\n",
    "        # 각 손가락에 대해\n",
    "        finger_tip = landmarks[tip] # landmarks[0]\n",
    "        # print(landmarks[8])\n",
    "        # print(finger_tip)\n",
    "        lower_joint = landmarks[joint]\n",
    "        if finger_tip[1] < lower_joint[1]:\n",
    "            finger_status[finger_names[tip]] = \"Open\" # fimger_names[8]은 index손가락의 이름을 반환함(즉 finger_name은 랜드마크 인덱스와 손가락 이름 간의 매핑을 가지고 있음 )\n",
    "        else:\n",
    "            finger_status[finger_names[tip]] = \"Closed\"\n",
    "\n",
    "    if finger_status[\"Thumb\"] == \"Open\": #엄지척\n",
    "        ret_message = 'ONE'\n",
    "    elif finger_status['Index'] == 'Closed' and finger_status['Middle'] == 'Closed' and \\\n",
    "       finger_status['Ring'] == 'Open' and finger_status['Pinky'] == 'Open':\n",
    "        ret_message = 'SAD'\n",
    "    elif finger_status['Index'] == 'Open' and finger_status['Middle'] == 'Open' and \\\n",
    "       finger_status['Ring'] == 'Closed' and finger_status['Pinky'] == 'Closed':\n",
    "        ret_message = 'BRI'\n",
    "    else:\n",
    "        ret_message = 'NON'\n",
    "    return ret_message\n",
    "#    return finger_status\n",
    "\n",
    "# Mediapipe 모듈 초기화\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils ## 랜드마크 연결선 그리기 위해 사용 \n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5)\n",
    "\n",
    "# 슬픈 표정 이미지 로드 (예: 'sad_face.png')\n",
    "sad_face_img = cv2.imread('sad_face.png', -1)  # -1은 알파 채널 포함\n",
    "# 웃는 이미지 로드 (예: 'smile.png')\n",
    "smile_img = cv2.imread('smile.png', -1)  # -1은 알파 채널 포함\n",
    "# 엄지척 이미지 로드 (예: 'thumb.png')\n",
    "thumb_img = cv2.imread('thumb.png', -1)  # -1은 알파 채널 포함\n",
    "\n",
    "hhul_img = cv2.imread('hhul.png', -1)  # -1은 알파 채널 포함\n",
    "\n",
    "# 웹캠 설정\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # Mediapipe에 사용할 이미지 형식으로 변환\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # 얼굴과 손 감지 수행\n",
    "    face_results = face_detection.process(image)\n",
    "    hand_results = hands.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    ih, iw, _ = image.shape\n",
    "\n",
    "    # 얼굴과 손의 위치를 분석\n",
    "    try:\n",
    "        if face_results.detections and hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                # 랜드마크와 연결선 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2) \n",
    "                )  # img: 그림 그릴 대상 이미지/ hand_landmarks:손에 대한 랜드마크 정보/ mp.hand.HAND_CONNECTIONS: 랜드마크 간 연결정보/ 초록색점 빨간색선 \n",
    "                # 손가락 랜드마크를 리스트로 변환\n",
    "                landmarks = [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark] # hand_landmarks.landmark에는 손의 각 랜드마크에 대한 정보가 포함되어 있습\n",
    "                # print(landmarks) #[(0.1,0.2,0.3), (0.4,0.5,0.6), .....]\n",
    "                # 손가락 포즈 분석\n",
    "                finger_pose = analyze_finger_pose(landmarks)\n",
    "                if finger_pose == 'SAD':\n",
    "                    overlay_image = sad_face_img\n",
    "                elif finger_pose == 'ONE':\n",
    "                    overlay_image = thumb_img\n",
    "                elif finger_pose == 'BRI':\n",
    "                    overlay_image = smile_img\n",
    "                else:\n",
    "                    overlay_image = hhul_img\n",
    "\n",
    "                # # 손가락 포즈 분석\n",
    "                # finger_pose = analyze_finger_pose(landmarks)\n",
    "                # # 분석 결과를 화면에 표시\n",
    "                # y = 20\n",
    "                # for finger, status in finger_pose.items():\n",
    "                #     cv2.putText(image, f\"{finger}: {status}\", (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "                #     y += 20\n",
    "\n",
    "\n",
    "            for detection in face_results.detections:\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "\n",
    "                image[y:y+h, x:x+w] = convertImag(x, y, w, h, image, overlay_image)\n",
    "        \n",
    "    # 결과 이미지 표시\n",
    "        cv2.imshow('Hand Over Face Detection', image)\n",
    "\n",
    "    # ESC를 누르면 종료\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "    except ValueError as e: \n",
    "        print(f\"ValueError Occur: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"unexpected Error occur:{e}\")\n",
    "    finally:\n",
    "        pass\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
